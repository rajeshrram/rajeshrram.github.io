---
layout: post
title: "Robots.txt"
permalink: "\\2009\11\robotstxt.html"
date: "2009-11-11 12:18:00"
updated: "2015-01-21 18:36:30"
description: 
categories: General
author: 
    name: "Rajeshkumar Ramasamy"
    url: "https://plus.google.com/103224277488233276143?rel=author"
    image: "//lh3.googleusercontent.com/-6529ZP6xOxE/AAAAAAAAAAI/AAAAAAAAGDQ/8tWd8ci28b4/s32-c/photo.jpg"
---

<div class="css-full-post-content js-full-post-content">
<div dir="ltr" style="text-align: left;" trbidi="on">Hi Friends,<br /><br />Did you hear anything about this robots.txt file .This file is important for web development .<br /><br />The <strong>Robot Exclusion Standard</strong>, also known as the <strong>Robots Exclusion Protocol</strong> or <strong>robots.txt protocol</strong><br /><br />is used to prevent files from <strong>web crawlers</strong> or <strong>Robots </strong>or <strong>Web Spiders</strong> .<br /><br /><strong>Web Crawlers</strong> ..What is this ? What is the purpose of this ? The answer is Web Crawlers are<br /><br />used(frequently used in search engines like Google ) to get data from <a href="http://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a> .<br /><br />How Search engines work ??<br /><div class="separator" style="clear: both; text-align: center;"></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-_w11_ktWZ-k/UhpiZRAuk2I/AAAAAAAAIJk/xngKkwsfVB0/s1600/searchenginechart.gif" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-_w11_ktWZ-k/UhpiZRAuk2I/AAAAAAAAIJk/xngKkwsfVB0/s320/searchenginechart.gif" height="256" width="320" /></a></div><br /><br /><br />1. Web Spiders(Google) are getting the data from the <a href="http://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a> and organizing the data<br /><br />in to their databases based on Meta Tags (this thing has been assigned for Index of this page).<br /><br />For example the web spiders get the meta tag as index(asp) and mapped to <a href="http://www.asp.net/" target="_blank">Asp.Net</a>.<br /><br />2. when we are searching the word ‘asp’ in Google , it searches the database(Google's Database-<br /><br />It was already filled by using Webcrawlers ) by using the keyword ‘asp’ and get the<br /><br />results(in the order of maximum hit counts(Rank)) like<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-F07dvslIUGI/UhpiZTesrdI/AAAAAAAAIJw/XoeZk-6stcQ/s1600/aspsearch.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-F07dvslIUGI/UhpiZTesrdI/AAAAAAAAIJw/XoeZk-6stcQ/s320/aspsearch.jpg" height="152" width="320" /></a></div><br /><br /><br />Now i am coming to that point <strong>robots.txt , </strong>this WebCrawler will get all datas from our web server.<br /><br />So we have to stop the web crawler to getting our personal datas or something you need<br /><br />to hide(example: login page) from our webserver, this is the time we need this <strong>Robot Exclusion Standard(robots.txt).</strong><br /><br />Step 1: You can add the pages(need for hide ) one by one in the robots.txt file.<br /><br />Step 2: Upload this file to your Web Server.<br /><br />That's It…<br /><div class="csharpcode"><br /><pre class="alt"><span class="lnum">   1:  </span>This example allows all robots to visit all files because</pre><br /><pre><span class="lnum">   2:  </span>the wildcard <span class="str">"*"</span>  specifies all robots:</pre><br /><pre class="alt"><span class="lnum">   3:  </span></pre><br /><pre><span class="lnum">   4:  </span>User-agent: *</pre><br /><pre class="alt"><span class="lnum">   5:  </span>Disallow:</pre><br /><pre><span class="lnum">   6:  </span>This example keeps all robots <span class="kwrd">out</span>:</pre><br /><pre class="alt"><span class="lnum">   7:  </span></pre><br /><pre><span class="lnum">   8:  </span>User-agent: *</pre><br /><pre class="alt"><span class="lnum">   9:  </span>Disallow: /</pre><br /><pre><span class="lnum">  10:  </span>This example allows all robots to visit all files because</pre><br /><pre class="alt"><span class="lnum">  11:  </span> the wildcard <span class="str">"*"</span> specifies all robots:</pre><br /><pre><span class="lnum">  12:  </span></pre><br /><pre class="alt"><span class="lnum">  13:  </span>User-agent: *</pre><br /><pre><span class="lnum">  14:  </span>Disallow:</pre><br /><pre class="alt"><span class="lnum">  15:  </span>This example keeps all robots <span class="kwrd">out</span>:</pre><br /><pre><span class="lnum">  16:  </span></pre><br /><pre class="alt"><span class="lnum">  17:  </span>User-agent: *</pre><br /><pre><span class="lnum">  18:  </span>Disallow: /</pre><br /></div>References:<br /><br />1. <a href="http://en.wikipedia.org/wiki/Robots_exclusion_standard" target="_blank">Robots.txt</a><br /><br /><span style="color: #333333;">2. <a href="http://computer.howstuffworks.com/search-engine.htm" target="_blank">How Search Engine Works</a></span><br /><br />Examples:<br /><br />1.<a href="http://www.google.com/robots.txt" target="_blank">Google robots.txt</a><br /><br />2.<a href="http://en.wikipedia.org/robots.txt" target="_blank">Wikipedia robots.txt</a></div>
</div>
<div class="css-full-comments-content js-full-comments-content">
<div class="css-full-comment js-full-comment">
  <div class="css-comment-user-link js-comment-user-link">
  <a href="http://www.rajeshrram.com/">
  <div class="css-comment-name js-comment-name">
    Rajeshkumar R
  </div>
  </a>
  <div class="css-comment-date js-comment-date">
    2009-12-24T12:08:35.000Z
  </div>
  </div>
  <div class="css-comment-content js-comment-content">
    hai
  </div>
  <br/>
</div>
</div>